{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "# Exam 4th of January 2024, 8.00-13.00 for the course 1MS041 (Introduction to Data Science / Introduktion till dataanalys)\n",
    "\n",
    "## Instructions:\n",
    "1. Complete the problems by following instructions.\n",
    "2. When done, submit this file with your solutions saved, following the instruction sheet.\n",
    "\n",
    "This exam has 3 problems for a total of 40 points, to pass you need\n",
    "20 points. The bonus will be added to the score of the exam and rounded afterwards.\n",
    "\n",
    "## Some general hints and information:\n",
    "* Try to answer all questions even if you are uncertain.\n",
    "* Comment your code, so that if you get the wrong answer I can understand how you thought\n",
    "this can give you some points even though the code does not run.\n",
    "* Follow the instruction sheet rigorously.\n",
    "* This exam is partially autograded, but your code and your free text answers are manually graded anonymously.\n",
    "* If there are any questions, please ask the exam guards, they will escalate it to me if necessary.\n",
    "\n",
    "## Tips for free text answers\n",
    "* Be VERY clear with your reasoning, there should be zero ambiguity in what you are referring to.\n",
    "* If you want to include math, you can write LaTeX in the Markdown cells, for instance `$f(x)=x^2$` will be rendered as $f(x)=x^2$ and `$$f(x) = x^2$$` will become an equation line, as follows\n",
    "$$f(x) = x^2$$\n",
    "Another example is `$$f_{Y \\mid X}(y,x) = P(Y = y \\mid X = x) = \\exp(\\alpha \\cdot x + \\beta)$$` which renders as\n",
    "$$f_{Y \\mid X}(y,x) = P(Y = y \\mid X = x) = \\exp(\\alpha \\cdot x + \\beta)$$\n",
    "\n",
    "## Finally some rules:\n",
    "* You may not communicate with others during the exam, for example:\n",
    "    * You cannot ask for help in Stack-Overflow or other such help forums during the Exam.\n",
    "    * You may not communicate with AI's, for instance ChatGPT.\n",
    "    * Your on-line and off-line activity is being monitored according to the examination rules.\n",
    "\n",
    "## Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Insert your anonymous exam ID as a string in the variable below\n",
    "examID=\"XXX\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "source": [
    "---\n",
    "## Exam vB, PROBLEM 1\n",
    "Maximum Points = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "source": [
    "\n",
    "In this problem you will do rejection sampling from complicated distributions, you will also be using your samples to compute certain integrals, a method known as Monte Carlo integration: (Keep in mind that choosing a good sampling distribution is often key to avoid too much rejection)\n",
    "\n",
    "1. [4p] Fill in the remaining part of the function `problem1_inversion` in order to produce samples from the below distribution using rejection sampling:\n",
    "\n",
    "$$\n",
    "    F[x] = \n",
    "    \\begin{cases}\n",
    "        0, & x \\leq 0 \\\\\n",
    "        \\frac{e^{x^2}-1}{e-1}, & 0 < x < 1 \\\\\n",
    "        1, & x \\geq 1\n",
    "    \\end{cases}\n",
    "$$\n",
    "\n",
    "2. [2p] Produce 100000 samples (**use fewer if it times-out and you cannot find a solution**) and put the answer in `problem1_samples` from the above distribution and plot the histogram together with the true density. *(There is a timeout decorator on this function and if it takes more than 10 seconds to generate 100000 samples it will timeout and it will count as if you failed to generate.)*\n",
    "3. [2p] Use the above 100000 samples (`problem1_samples`) to approximately compute the integral\n",
    "\n",
    "$$\n",
    "    \\int_0^{1} \\sin(x) \\frac{2e^{x^2} x}{e-1} dx\n",
    "$$\n",
    "and store the result in `problem1_integral`.\n",
    "\n",
    "4. [2p] Use Hoeffdings inequality to produce a 95\\% confidence interval of the integral above and store the result as a tuple in the variable `problem1_interval`\n",
    "\n",
    "5. [4p] Fill in the remaining part of the function `problem1_inversion_2` in order to produce samples from the below distribution using rejection sampling:\n",
    "$$\n",
    "    F[x] = \n",
    "    \\begin{cases}\n",
    "        0, & x \\leq 0 \\\\\n",
    "        20xe^{20-1/x}, & 0 < x < \\frac{1}{20} \\\\\n",
    "        1, & x \\geq \\frac{1}{20}\n",
    "    \\end{cases}\n",
    "$$\n",
    "Hint: this is tricky because if you choose the wrong sampling distribution you reject at least 9 times out of 10. You will get points based on how long your code takes to create a certain number of samples, if you choose the correct sampling distribution you can easily create 100000 samples within 2 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94669547 0.54763896 0.94763881 0.92840767 0.97882783 0.99489782\n",
      " 0.81209003 0.44169877 0.98558345 0.83360418]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Part 1\n",
    "import numpy as np\n",
    "# from Utils import timeout\n",
    "\n",
    "# @timeout\n",
    "def problem1_inversion(n_samples=1):\n",
    "    # Distribution from part 1\n",
    "    # write the code in this function to produce samples from the distribution in the assignment\n",
    "    # Make sure you choose a good sampling distribution to avoid unnecessary rejections\n",
    "\n",
    "    M = 3.17\n",
    "    out = []\n",
    "    while len(out) < n_samples:\n",
    "        x = np.random.uniform()\n",
    "        u = np.random.uniform()\n",
    "        if u <= ((2*x*np.exp(x**2))/(np.e-1) / M):\n",
    "            out.append(x)\n",
    "\n",
    "\n",
    "    # Return a numpy array of length n_samples\n",
    "    return np.array(out)\n",
    "\n",
    "print(problem1_inversion(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Part 2\n",
    "\n",
    "problem1_samples = problem1_inversion(100000)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_vals = np.linspace(0, 1, 100)\n",
    "y_vals = (2*x_vals*np.exp(x_vals**2))/(np.e-1)\n",
    "plt.hist(problem1_samples, bins=50, density=True, label=\"Samples\")\n",
    "plt.plot(x_vals, y_vals, label=\"True Density\")\n",
    "plt.legend()\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [],
   "source": [
    "# Part 3\n",
    "\n",
    "problem1_integral = np.mean(np.sin(problem1_samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(0.6476352640378807), np.float64(0.6562246522048155)]\n"
     ]
    }
   ],
   "source": [
    "# Part 4\n",
    "alpha = 0.05\n",
    "n = 100000\n",
    "b = 1\n",
    "a = 0\n",
    "\n",
    "epsilon = (b - a) * np.sqrt(np.log(2/alpha) / (2 * n))\n",
    "\n",
    "problem1_interval = [problem1_integral - epsilon, problem1_integral + epsilon]\n",
    "print(problem1_interval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04341239 0.04447898 0.04264496 ... 0.04382991 0.04685096 0.04223259]\n"
     ]
    }
   ],
   "source": [
    "# Part 5\n",
    "\n",
    "def problem1_inversion_2(n_samples=1):\n",
    "    # Distribution from part 2\n",
    "    # write the code in this function to produce samples from the distribution in the assignment\n",
    "    # Make sure you choose a good sampling distribution to avoid unnecessary rejections\n",
    "\n",
    "    # Return a numpy array of length n_samples\n",
    "\n",
    "    M = 22\n",
    "    out = []\n",
    "\n",
    "    while len(out) < n_samples:\n",
    "        x = np.random.uniform(0, 1/20)\n",
    "        u = np.random.uniform(0, 1/20)\n",
    "\n",
    "        if u <= (20*np.exp(20 - (1/x)) * (1 + (1/x))) / (M * 20):\n",
    "            out.append(x)\n",
    "\n",
    "    return np.array(out)\n",
    "print(problem1_inversion_2(100000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "source": [
    "---\n",
    "#### Local Test for Exam vB, PROBLEM 1\n",
    "Evaluate cell below to make sure your answer is valid.                             You **should not** modify anything in the cell below when evaluating it to do a local test of                             your solution.\n",
    "You may need to include and evaluate code snippets from lecture notebooks in cells above to make the local test work correctly sometimes (see error messages for clues). This is meant to help you become efficient at recalling materials covered in lectures that relate to this problem. Such local tests will generally not be available in the exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good, your problem1_inversion returns a numpy array\n",
      "Good, your problem1_samples is a numpy array\n",
      "Good, your problem1_integral is a float\n",
      "Good, your problem1_interval is a tuple or list of length 2\n",
      "Good, your problem1_inversion_2 returns a numpy array\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# This cell is just to check that you got the correct formats of your answer\n",
    "import numpy as np\n",
    "try:\n",
    "    assert(isinstance(problem1_inversion(10), np.ndarray)) \n",
    "except:\n",
    "    print(\"Try again. You should return a numpy array from problem1_inversion\")\n",
    "else:\n",
    "    print(\"Good, your problem1_inversion returns a numpy array\")\n",
    "\n",
    "try:\n",
    "    assert(isinstance(problem1_samples, np.ndarray)) \n",
    "except:\n",
    "    print(\"Try again. your problem1_samples is not a numpy array\")\n",
    "else:\n",
    "    print(\"Good, your problem1_samples is a numpy array\")\n",
    "\n",
    "try:\n",
    "    assert(isinstance(problem1_integral, float)) \n",
    "except:\n",
    "    print(\"Try again. your problem1_integral is not a float\")\n",
    "else:\n",
    "    print(\"Good, your problem1_integral is a float\")\n",
    "\n",
    "try:\n",
    "    assert(isinstance(problem1_interval, list) or isinstance(problem1_interval, tuple)) , \"problem1_interval not a tuple or list\"\n",
    "    assert(len(problem1_interval) == 2) , \"problem1_interval does not have length 2, it should have a lower bound and an upper bound\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your problem1_interval is a tuple or list of length 2\")\n",
    "\n",
    "try:\n",
    "    assert(isinstance(problem1_inversion_2(10), np.ndarray)) \n",
    "except:\n",
    "    print(\"Try again. You should return a numpy array from problem1_inversion_2\")\n",
    "else:\n",
    "    print(\"Good, your problem1_inversion_2 returns a numpy array\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "source": [
    "---\n",
    "## Exam vB, PROBLEM 2\n",
    "Maximum Points = 13"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "source": [
    "\n",
    "Let us build a proportional model ($\\mathbb{P}(Y=1 \\mid X) = G(\\beta_0+\\beta \\cdot X)$ where $G$ is the logistic function) for the spam vs not spam data. Here we assume that the features are presence vs not presence of a word, let $X_1,X_2,X_3$ denote the presence (1) or absence (0) of the words $(\"free\", \"prize\", \"win\")$.\n",
    "\n",
    "1. [2p] Load the file `data/spam.csv` and create two numpy arrays, `problem2_X` which has shape (n_emails,3) where each feature in `problem2_X` corresponds to $X_1,X_2,X_3$ from above, `problem2_Y` which has shape **(n_emails,)** and consists of a $1$ if the email is spam and $0$ if it is not. Split this data into a train-calibration-test sets where we have the split $40\\%$, $20\\%$, $40\\%$, put this data in the designated variables in the code cell.\n",
    "\n",
    "2. [4p] Follow the calculation from the lecture notes where we derive the logistic regression and implement the final loss function inside the class `ProportionalSpam`. You can use the `Test` cell to check that it gives the correct value for a test-point.\n",
    "\n",
    "3. [4p] Train the model `problem2_ps` on the training data. The goal is to calibrate the probabilities output from the model. Start by creating a new variable `problem2_X_pred` (shape `(n_samples,1)`) which consists of the predictions of `problem2_ps` on the calibration dataset. Then train a calibration model using `sklearn.tree.DecisionTreeRegressor`, store this trained model in `problem2_calibrator`.\n",
    "\n",
    "4. [3p] Use the trained model `problem2_ps` and the calibrator `problem2_calibrator` to make final predictions on the testing data, store the prediction in `problem2_final_predictions`. Compute the $0-1$ test-loss and store it in `problem2_01_loss` and provide a $99\\%$ confidence interval of it, store this in the variable `problem2_interval`, this should again be a tuple as in **problem1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2228, 3) (1115, 3) (2229, 3) (2228,) (1115,) (2229,)\n"
     ]
    }
   ],
   "source": [
    "# Part 1\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/spam.csv\", encoding=\"latin-1\")\n",
    "\n",
    "emails = df[\"v2\"]\n",
    "featureX = []\n",
    "for email in emails:\n",
    "    email_lowered = email.lower()\n",
    "    words = [0, 0, 0]\n",
    "    if \"free\" in email_lowered:\n",
    "        words[0] = 1\n",
    "    if \"prize\" in email_lowered:\n",
    "        words[1] = 1\n",
    "    if \"win\" in email_lowered:\n",
    "        words[2] = 1\n",
    "    featureX.append(words)\n",
    "\n",
    "problem2_X = pd.DataFrame.from_records(featureX, columns=[\"X1\", \"X2\", \"X3\"])\n",
    "problem2_Y = df[\"v1\"].map({\"ham\": 0, \"spam\": 1})\n",
    "\n",
    "\n",
    "split1 = int(0.4 * df.shape[0])\n",
    "split2 = int(0.6 * df.shape[0])\n",
    "\n",
    "problem2_X_train = problem2_X[:split1]\n",
    "problem2_X_calib = problem2_X[split1:split2]\n",
    "problem2_X_test = problem2_X[split2:]\n",
    "\n",
    "problem2_Y_train = problem2_Y[:split1]\n",
    "problem2_Y_calib = problem2_Y[split1:split2]\n",
    "problem2_Y_test = problem2_Y[split2:]\n",
    "\n",
    "print(problem2_X_train.shape,problem2_X_calib.shape,problem2_X_test.shape,problem2_Y_train.shape,problem2_Y_calib.shape,problem2_Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# Part 2\n",
    "\n",
    "class ProportionalSpam(object):\n",
    "    def __init__(self):\n",
    "        self.coeffs = None\n",
    "        self.result = None\n",
    "    \n",
    "    # define the objective/cost/loss function we want to minimise\n",
    "    def loss(self,X,Y,coeffs):\n",
    "        Z = 2*Y - 1\n",
    "        expression = np.log(1 + np.exp(-Z*(coeffs[0] + np.dot(X, coeffs[1:]))))\n",
    "        return np.mean(expression)\n",
    "\n",
    "    def fit(self,X,Y):\n",
    "        import numpy as np\n",
    "        from scipy import optimize\n",
    "\n",
    "        #Use the f above together with an optimization method from scipy\n",
    "        #to find the coefficients of the model\n",
    "        opt_loss = lambda coeffs: self.loss(X,Y,coeffs)\n",
    "        initial_arguments = np.zeros(shape=X.shape[1]+1)\n",
    "        self.result = optimize.minimize(opt_loss, initial_arguments,method='cg')\n",
    "        self.coeffs = self.result.x\n",
    "    \n",
    "    def predict(self,X):\n",
    "        #Use the trained model to predict Y\n",
    "        if (self.coeffs is not None):\n",
    "            G = lambda x: np.exp(x)/(1+np.exp(x))\n",
    "            return np.round(10*G(np.dot(X,self.coeffs[1:])+self.coeffs[0]))/10 # This rounding is to help you with the calibration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1115,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-1.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-1.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>DecisionTreeRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeRegressor.html\">?<span>Documentation for DecisionTreeRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('criterion',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeRegressor.html#:~:text=criterion,-%7B%22squared_error%22%2C%20%22friedman_mse%22%2C%20%22absolute_error%22%2C%20%20%20%20%20%20%20%20%20%20%20%20%20%22poisson%22%7D%2C%20default%3D%22squared_error%22\">\n",
       "            criterion\n",
       "            <span class=\"param-doc-description\">criterion: {\"squared_error\", \"friedman_mse\", \"absolute_error\",             \"poisson\"}, default=\"squared_error\"<br><br>The function to measure the quality of a split. Supported criteria<br>are \"squared_error\" for the mean squared error, which is equal to<br>variance reduction as feature selection criterion and minimizes the L2<br>loss using the mean of each terminal node, \"friedman_mse\", which uses<br>mean squared error with Friedman's improvement score for potential<br>splits, \"absolute_error\" for the mean absolute error, which minimizes<br>the L1 loss using the median of each terminal node, and \"poisson\" which<br>uses reduction in the half mean Poisson deviance to find splits.<br><br>.. versionadded:: 0.18<br>   Mean Absolute Error (MAE) criterion.<br><br>.. versionadded:: 0.24<br>    Poisson deviance criterion.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;squared_error&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('splitter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeRegressor.html#:~:text=splitter,-%7B%22best%22%2C%20%22random%22%7D%2C%20default%3D%22best%22\">\n",
       "            splitter\n",
       "            <span class=\"param-doc-description\">splitter: {\"best\", \"random\"}, default=\"best\"<br><br>The strategy used to choose the split at each node. Supported<br>strategies are \"best\" to choose the best split and \"random\" to choose<br>the best random split.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;best&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeRegressor.html#:~:text=max_depth,-int%2C%20default%3DNone\">\n",
       "            max_depth\n",
       "            <span class=\"param-doc-description\">max_depth: int, default=None<br><br>The maximum depth of the tree. If None, then nodes are expanded until<br>all leaves are pure or until all leaves contain less than<br>min_samples_split samples.<br><br>For an example of how ``max_depth`` influences the model, see<br>:ref:`sphx_glr_auto_examples_tree_plot_tree_regression.py`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_split',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeRegressor.html#:~:text=min_samples_split,-int%20or%20float%2C%20default%3D2\">\n",
       "            min_samples_split\n",
       "            <span class=\"param-doc-description\">min_samples_split: int or float, default=2<br><br>The minimum number of samples required to split an internal node:<br><br>- If int, then consider `min_samples_split` as the minimum number.<br>- If float, then `min_samples_split` is a fraction and<br>  `ceil(min_samples_split * n_samples)` are the minimum<br>  number of samples for each split.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeRegressor.html#:~:text=min_samples_leaf,-int%20or%20float%2C%20default%3D1\">\n",
       "            min_samples_leaf\n",
       "            <span class=\"param-doc-description\">min_samples_leaf: int or float, default=1<br><br>The minimum number of samples required to be at a leaf node.<br>A split point at any depth will only be considered if it leaves at<br>least ``min_samples_leaf`` training samples in each of the left and<br>right branches.  This may have the effect of smoothing the model,<br>especially in regression.<br><br>- If int, then consider `min_samples_leaf` as the minimum number.<br>- If float, then `min_samples_leaf` is a fraction and<br>  `ceil(min_samples_leaf * n_samples)` are the minimum<br>  number of samples for each node.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_weight_fraction_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeRegressor.html#:~:text=min_weight_fraction_leaf,-float%2C%20default%3D0.0\">\n",
       "            min_weight_fraction_leaf\n",
       "            <span class=\"param-doc-description\">min_weight_fraction_leaf: float, default=0.0<br><br>The minimum weighted fraction of the sum total of weights (of all<br>the input samples) required to be at a leaf node. Samples have<br>equal weight when sample_weight is not provided.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeRegressor.html#:~:text=max_features,-int%2C%20float%20or%20%7B%22sqrt%22%2C%20%22log2%22%7D%2C%20default%3DNone\">\n",
       "            max_features\n",
       "            <span class=\"param-doc-description\">max_features: int, float or {\"sqrt\", \"log2\"}, default=None<br><br>The number of features to consider when looking for the best split:<br><br>- If int, then consider `max_features` features at each split.<br>- If float, then `max_features` is a fraction and<br>  `max(1, int(max_features * n_features_in_))` features are considered at each<br>  split.<br>- If \"sqrt\", then `max_features=sqrt(n_features)`.<br>- If \"log2\", then `max_features=log2(n_features)`.<br>- If None, then `max_features=n_features`.<br><br>Note: the search for a split does not stop until at least one<br>valid partition of the node samples is found, even if it requires to<br>effectively inspect more than ``max_features`` features.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeRegressor.html#:~:text=random_state,-int%2C%20RandomState%20instance%20or%20None%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance or None, default=None<br><br>Controls the randomness of the estimator. The features are always<br>randomly permuted at each split, even if ``splitter`` is set to<br>``\"best\"``. When ``max_features < n_features``, the algorithm will<br>select ``max_features`` at random at each split before finding the best<br>split among them. But the best found split may vary across different<br>runs, even if ``max_features=n_features``. That is the case, if the<br>improvement of the criterion is identical for several splits and one<br>split has to be selected at random. To obtain a deterministic behaviour<br>during fitting, ``random_state`` has to be fixed to an integer.<br>See :term:`Glossary <random_state>` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaf_nodes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeRegressor.html#:~:text=max_leaf_nodes,-int%2C%20default%3DNone\">\n",
       "            max_leaf_nodes\n",
       "            <span class=\"param-doc-description\">max_leaf_nodes: int, default=None<br><br>Grow a tree with ``max_leaf_nodes`` in best-first fashion.<br>Best nodes are defined as relative reduction in impurity.<br>If None then unlimited number of leaf nodes.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_impurity_decrease',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeRegressor.html#:~:text=min_impurity_decrease,-float%2C%20default%3D0.0\">\n",
       "            min_impurity_decrease\n",
       "            <span class=\"param-doc-description\">min_impurity_decrease: float, default=0.0<br><br>A node will be split if this split induces a decrease of the impurity<br>greater than or equal to this value.<br><br>The weighted impurity decrease equation is the following::<br><br>    N_t / N * (impurity - N_t_R / N_t * right_impurity<br>                        - N_t_L / N_t * left_impurity)<br><br>where ``N`` is the total number of samples, ``N_t`` is the number of<br>samples at the current node, ``N_t_L`` is the number of samples in the<br>left child, and ``N_t_R`` is the number of samples in the right child.<br><br>``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,<br>if ``sample_weight`` is passed.<br><br>.. versionadded:: 0.19</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ccp_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeRegressor.html#:~:text=ccp_alpha,-non-negative%20float%2C%20default%3D0.0\">\n",
       "            ccp_alpha\n",
       "            <span class=\"param-doc-description\">ccp_alpha: non-negative float, default=0.0<br><br>Complexity parameter used for Minimal Cost-Complexity Pruning. The<br>subtree with the largest cost complexity that is smaller than<br>``ccp_alpha`` will be chosen. By default, no pruning is performed. See<br>:ref:`minimal_cost_complexity_pruning` for details. See<br>:ref:`sphx_glr_auto_examples_tree_plot_cost_complexity_pruning.py`<br>for an example of such pruning.<br><br>.. versionadded:: 0.22</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotonic_cst',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeRegressor.html#:~:text=monotonic_cst,-array-like%20of%20int%20of%20shape%20%28n_features%29%2C%20default%3DNone\">\n",
       "            monotonic_cst\n",
       "            <span class=\"param-doc-description\">monotonic_cst: array-like of int of shape (n_features), default=None<br><br>Indicates the monotonicity constraint to enforce on each feature.<br>  - 1: monotonic increase<br>  - 0: no constraint<br>  - -1: monotonic decrease<br><br>If monotonic_cst is None, no constraints are applied.<br><br>Monotonicity constraints are not supported for:<br>  - multioutput regressions (i.e. when `n_outputs_ > 1`),<br>  - regressions trained on data with missing values.<br><br>Read more in the :ref:`User Guide <monotonic_cst_gbdt>`.<br><br>.. versionadded:: 1.4</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-1');</script></body>"
      ],
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part 3\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "problem2_ps = ProportionalSpam()\n",
    "problem2_ps.fit(problem2_X_train, problem2_Y_train)\n",
    "\n",
    "problem2_X_pred = problem2_ps.predict(problem2_X_calib)\n",
    "print(problem2_X_pred.shape)\n",
    "\n",
    "problem2_calibrator = DecisionTreeRegressor()\n",
    "problem2_calibrator.fit(problem2_X_pred.reshape(-1, 1), problem2_Y_calib)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07101167 0.07101167 0.07101167 ... 0.07101167 0.73170732 0.07101167]\n",
      "0.10318528488111256\n",
      "[np.float64(0.06871070739031301), np.float64(0.1376598623719121)]\n"
     ]
    }
   ],
   "source": [
    "# Part 4\n",
    "import sklearn as skl\n",
    "# These are the predicted probabilities\n",
    "predictions = problem2_ps.predict(problem2_X_test)\n",
    "problem2_final_predictions = problem2_calibrator.predict(predictions.reshape(-1, 1))\n",
    "\n",
    "\n",
    "print(problem2_final_predictions)\n",
    "# In order to compute this loss we first need to convert the predicted probabilities to a decision\n",
    "# recall the Bayes classifier?\n",
    "clf = [1 if x > 0.5 else 0 for x in problem2_final_predictions]\n",
    "problem2_01_loss = skl.metrics.zero_one_loss(clf, problem2_Y_test)\n",
    "print(problem2_01_loss)\n",
    "\n",
    "alpha = 0.01\n",
    "n = problem2_final_predictions.shape[0]\n",
    "b = 1\n",
    "a = 0\n",
    "\n",
    "epsilon = (b - a) * np.sqrt(np.log(2/alpha) / (2 * n))\n",
    "\n",
    "# Recall the interval is given as a tuple (a,b) or a list [a,b]\n",
    "problem2_interval = [problem2_01_loss - epsilon, problem2_01_loss + epsilon]\n",
    "print(problem2_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "source": [
    "---\n",
    "#### Local Test for Exam vB, PROBLEM 2\n",
    "Evaluate cell below to make sure your answer is valid.                             You **should not** modify anything in the cell below when evaluating it to do a local test of                             your solution.\n",
    "You may need to include and evaluate code snippets from lecture notebooks in cells above to make the local test work correctly sometimes (see error messages for clues). This is meant to help you become efficient at recalling materials covered in lectures that relate to this problem. Such local tests will generally not be available in the exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your loss was correct for a test point\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import numpy as np\n",
    "    test_instance = ProportionalSpam()\n",
    "    test_loss = test_instance.loss(np.array([[1,0,1],[0,1,1]]),np.array([1,0]),np.array([1.2,0.4,0.3,0.9]))\n",
    "    assert (np.abs(test_loss-1.2828629432232497) < 1e-6)\n",
    "    print(\"Your loss was correct for a test point\")\n",
    "except:\n",
    "    print(\"Your loss was not correct on a test point\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "source": [
    "---\n",
    "## Exam vB, PROBLEM 3\n",
    "Maximum Points = 13"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "source": [
    "\n",
    "Consider the following four Markov chains, answer each question for all chains:\n",
    "\n",
    "<img width=\"400px\" src=\"pictures/MarkovA.png\">Markov chain A</img>\n",
    "<img width=\"400px\" src=\"pictures/MarkovB.png\">Markov chain B</img>\n",
    "<img width=\"400px\" src=\"pictures/MarkovC.png\">Markov chain C</img>\n",
    "<img width=\"400px\" src=\"pictures/MarkovD.png\">Markov chain D</img>\n",
    "\n",
    "1. [2p] What is the transition matrix?\n",
    "2. [2p] Is the Markov chain irreducible?\n",
    "3. [3p] Is the Markov chain aperiodic? What is the period for each state?\n",
    "4. [3p] Does the Markov chain have a stationary distribution, and if so, what is it?\n",
    "5. [3p] Is the Markov chain reversible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# PART 1\n",
    "import numpy as np\n",
    "#------------------------TRANSITION MATRIX -------------------------------\n",
    "# Answer each one by supplying the transition matrix as a numpy array\n",
    "# of shape (n_states,n_states), where state (A,B,...) corresponds to index (0,1,...)\n",
    "\n",
    "problem3_A    = np.array([[0.8, 0.2, 0, 0], [0.6, 0.2, 0.2, 0], [0, 0.4, 0, 0.6], [0, 0, 0.8, 0.2]])\n",
    "problem3_B    = np.array([[0, 0.2, 0, 0.8], [0, 0, 1, 0], [0, 1, 0, 0], [0.5, 0, 0.5, 0]])\n",
    "problem3_C    = np.array([[0.2, 0.3, 0, 0, 0.5], [0.2, 0.2, 0.6, 0, 0], [0, 0.4, 0, 0.6, 0], [0, 0, 0, 0.6, 0.4], [0, 0, 0, 0.4, 0.6]])\n",
    "problem3_D    = np.array([[0.8, 0.2, 0, 0], [0.6, 0.2, 0.2, 0], [0, 0.4, 0, 0.6], [0.1, 0, 0.7, 0.2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True False False True\n"
     ]
    }
   ],
   "source": [
    "# PART 2\n",
    "#------------------------REDUCIBLE -------------------------------\n",
    "# Answer each one with a True or False\n",
    "def is_irreducible(P):\n",
    "    n = len(P)\n",
    "    I = np.eye(n)\n",
    "\n",
    "    return np.all(np.linalg.matrix_power(I + P, n-1) > 0)\n",
    "\n",
    "\n",
    "problem3_A_irreducible = is_irreducible(problem3_A)\n",
    "problem3_B_irreducible = is_irreducible(problem3_B)\n",
    "problem3_C_irreducible = is_irreducible(problem3_C)\n",
    "problem3_D_irreducible = is_irreducible(problem3_D)\n",
    "print(problem3_A_irreducible, problem3_B_irreducible, problem3_C_irreducible, problem3_D_irreducible)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# PART 3\n",
    "#------------------------APERIODIC-------------------------------\n",
    "# Answer each one with a True or False\n",
    "\n",
    "problem3_A_is_aperiodic = True # Is irreducible and has self-loop\n",
    "problem3_B_is_aperiodic = False # Non irreducible and length from b-c-b = 2 != 1\n",
    "problem3_C_is_aperiodic = True # Non-irreducible but has self loop in trap\n",
    "problem3_D_is_aperiodic = True # Is irreducible and has self loop\n",
    "\n",
    "# Answer the following with the period of the states as a numpy array\n",
    "# of shape (n_states,)\n",
    "\n",
    "problem3_A_periods = 1\n",
    "problem3_B_periods = 2\n",
    "problem3_C_periods = 1\n",
    "problem3_D_periods = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.61538462 0.20512821 0.1025641  0.07692308] [5.55111512e-16 5.00000000e-01 5.00000000e-01 6.10622664e-16] [1.71111424e-16 0.00000000e+00 7.60495219e-17 5.00000000e-01\n",
      " 5.00000000e-01] [0.64516129 0.20430108 0.08602151 0.06451613]\n"
     ]
    }
   ],
   "source": [
    "# PART 4\n",
    "#------------------------STATIONARY DISTRIBUTION-----------------\n",
    "# Answer each one with a True or False\n",
    "\n",
    "def find_stationary(P):\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(P.T)\n",
    "    idx = np.argmin(np.abs(eigenvalues - 1.0))\n",
    "    steady_state = np.real(eigenvectors[:, idx])\n",
    "    return steady_state / steady_state.sum()\n",
    "\n",
    "problem3_A_has_stationary = True\n",
    "problem3_B_has_stationary = True\n",
    "problem3_C_has_stationary = True\n",
    "problem3_D_has_stationary = True\n",
    "\n",
    "# Answer the following with the stationary distribution as a numpy array of shape (n_states,)\n",
    "# if the Markov chain has a stationary distribution otherwise answer with False\n",
    "\n",
    "problem3_A_stationary_dist = find_stationary(problem3_A)\n",
    "problem3_B_stationary_dist = find_stationary(problem3_B) # non-irreducible matrices dont have a stationary distribution\n",
    "problem3_C_stationary_dist = find_stationary(problem3_C)\n",
    "problem3_D_stationary_dist = find_stationary(problem3_D)\n",
    "print(problem3_A_stationary_dist, problem3_B_stationary_dist, problem3_C_stationary_dist, problem3_D_stationary_dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True True False\n"
     ]
    }
   ],
   "source": [
    "# PART 5\n",
    "#------------------------REVERSIBLE-----------------\n",
    "# Answer each one with a True or False\n",
    "\n",
    "def is_reversible(P, stat_dist):\n",
    "    for i in range(len(P)):\n",
    "        for j in range(len(P)):\n",
    "            if not np.isclose(P[i][j] * stat_dist[i], P[j][i] * stat_dist[j]):\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "problem3_A_is_reversible = is_reversible(problem3_A, problem3_A_stationary_dist)\n",
    "problem3_B_is_reversible = is_reversible(problem3_B, problem3_B_stationary_dist)\n",
    "problem3_C_is_reversible = is_reversible(problem3_C, problem3_C_stationary_dist)\n",
    "problem3_D_is_reversible = is_reversible(problem3_D, problem3_D_stationary_dist)\n",
    "print(problem3_A_is_reversible, problem3_B_is_reversible, problem3_C_is_reversible, problem3_D_is_reversible)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  },
  "lx_assignment_number": "vB",
  "lx_course_instance": "2023",
  "lx_course_name": "Introduction to Data Science",
  "lx_course_number": "1MS041"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
