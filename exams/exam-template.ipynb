{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0960f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b217ac",
   "metadata": {},
   "source": [
    "PROBLEM 1: Data analysis using markov chians \n",
    "\n",
    "In this problem, you will empirically analyze a Markov chain \n",
    "with a finite state space. Transition probabilities are unknown.\n",
    "\n",
    "The state space is:\n",
    "    S = {0, 1, 2, 3}\n",
    "\n",
    "You are given the data for the observed X_t for t  = 0..19\n",
    "\n",
    "Tasks:\n",
    "1. Estimate the transition matrix P from the observed transitions.\n",
    "2. Verify that the estimated matrix is a probability transition matrix.\n",
    "3. Compute the stationary distribution pi of the chain.\n",
    "4. Simulate the chain using the estimated transition matrix\n",
    "5. Compute the expected hitting times via\n",
    "\n",
    "   (a) Simulation\n",
    "\n",
    "   (b) Solving linear equations (analytical hitting times). \n",
    "\n",
    "Compare the estimates and interpret the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a471499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# state space\n",
    "S = [0, 1, 2, 3]\n",
    "N_states = len(S)\n",
    "\n",
    "# Observed transitions: each row is (current_state, next_state)\n",
    "X_t = np.array([\n",
    "    [0, 1],\n",
    "    [1, 2],\n",
    "    [2, 3],\n",
    "    [3, 0],\n",
    "    [0, 1],\n",
    "    [1, 1],\n",
    "    [1, 2],\n",
    "    [2, 2],\n",
    "    [2, 3],\n",
    "    [3, 3],\n",
    "    [3, 0],\n",
    "    [0, 2],\n",
    "    [2, 1],\n",
    "    [1, 3],\n",
    "    [3, 1],\n",
    "    [1, 0],\n",
    "    [0, 0],\n",
    "    [0, 1],\n",
    "    [1, 2],\n",
    "    [2, 0],\n",
    "], dtype=int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c22d60",
   "metadata": {},
   "source": [
    "Below are methods that you need to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "3b339dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1\n",
    "def comp_transition_matrix(transitions, n_states):\n",
    "    \"\"\"\n",
    "    Estimate the transition matrix P from observed transitions.\n",
    "\n",
    "    Args:\n",
    "        transitions: array of shape (n_samples, 2)\n",
    "        n_states: number of states\n",
    "\n",
    "    Returns:\n",
    "        P_hat: estimated transition matrix\n",
    "    \"\"\"\n",
    "    P_hat = np.zeros((n_states, n_states))\n",
    "    \n",
    "    # implement P_hat\n",
    "\n",
    "    for i in range(len(P_hat)):\n",
    "        for j in range(len(P_hat)):\n",
    "            count_ij = 0\n",
    "            count_i = 0\n",
    "            for k in transitions:\n",
    "                if np.array_equal(k, [i, j]):\n",
    "                    count_ij += 1\n",
    "                if k[0] == i:\n",
    "                    count_i += 1\n",
    "            \n",
    "            P_hat[i][j] = count_ij / count_i\n",
    "    return P_hat\n",
    "\n",
    "#  1.2\n",
    "def is_transition_matrix(P):\n",
    "    \"\"\"\n",
    "    Check if P is a transition matrix.\n",
    "    \"\"\"\n",
    "\n",
    "    # implement the check here\n",
    "    for r in range(len(P)):\n",
    "        if not np.isclose(np.sum(P[r]), 1):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "# 1.3\n",
    "def stationary_distribution(P):\n",
    "    \"\"\"\n",
    "    Compute stationary distribution\n",
    "    \"\"\"\n",
    "\n",
    "    # Here you implement the method for computing pi. Remember that we did it during lessons - and there are at least 2 ways of computing pi. You can choose either of them\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(P.T)\n",
    "    idx = np.argmin(np.abs(eigenvalues - 1.0))\n",
    "    steady_state = np.real(eigenvectors[:, idx])\n",
    "    pi = steady_state / steady_state.sum()\n",
    "    \n",
    "    return pi\n",
    "\n",
    "\n",
    "\n",
    "def simulate_chain(P, start_state, n_steps):\n",
    "    \"\"\"\n",
    "    Simulate a Markov chain trajectory with a fixed random seed.\n",
    "\n",
    "    Returns: array of visited states of length n_steps + 1\n",
    "    \"\"\"\n",
    "    seed = 1234 # don't change that\n",
    "    \n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "\n",
    "    path = np.zeros(n_steps + 1, dtype=int)\n",
    "    path[0] = start_state\n",
    "\n",
    "    states = np.arange(len(P))\n",
    "\n",
    "    #  sample next states using rng.choice\n",
    "    for i in range(1, n_steps + 1, 1):\n",
    "        path[i] = rng.choice(states, p=P[path[i-1]])\n",
    "    return path\n",
    "\n",
    "\n",
    "def hitting_times_sim(P, start_state, n_sim=10_000):\n",
    "    \"\"\"\n",
    "    Estimate expected hitting times E[T_{start -> j}] for ALL states j.\n",
    "\n",
    "    Returns:\n",
    "        est: 1D array, where est[j] the estimated expected steps to hit state j from start_state. \n",
    "    \"\"\"\n",
    "    \n",
    "    est = np.full(N_states, np.nan, dtype=float)\n",
    "    seed = 1234\n",
    "\n",
    "    # Find simulation estimates of hitting time for all states 0,1, 2, 3\n",
    "    times = []\n",
    "    for _ in range(n_sim):\n",
    "        state = start_state\n",
    "        states = np.arange(len(P))\n",
    "        done = np.full(len(P), False, dtype=bool)\n",
    "        ht = np.full(N_states, np.nan, dtype=float)\n",
    "        t = 0\n",
    "        while t < n_sim:\n",
    "            t += 1\n",
    "            for i in range(len(P)):\n",
    "                if state == states[i] and not done[i]:\n",
    "                    ht[i] = t\n",
    "                    done[i] = True\n",
    "            if not False in done:\n",
    "                break\n",
    "            state = np.random.choice(states, p=P[state])\n",
    "        times.append(ht)\n",
    "    est = np.mean(times, axis=0)\n",
    "    return est\n",
    "\n",
    "\n",
    "def theoretical_hitting_times(P, start_state):\n",
    "\n",
    "    hit_theor = np.full(N_states, np.nan, dtype=float)\n",
    "    \n",
    "    # here you will solve a system of equations to find analytical hitting times.\n",
    "    # Hint: remember that, for start_state = j, the hitting time of j is always 1. \n",
    "\n",
    "    for target in range(len(P)):\n",
    "        if target == start_state:\n",
    "            hit_theor[target] = 1\n",
    "            continue\n",
    "\n",
    "        idx = [i for i in range(len(P)) if i != target]\n",
    "        Q = P[np.ix_(idx, idx)]\n",
    "\n",
    "        I = np.eye(len(idx))\n",
    "        A = I - Q\n",
    "        b = np.ones(len(idx))\n",
    "\n",
    "        x = np.linalg.solve(A, b)\n",
    "        hit_theor[target] = x[idx.index(start_state)]\n",
    "\n",
    "    \n",
    "    return hit_theor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f250cf14",
   "metadata": {},
   "source": [
    "When you are done, run the following cell (no need to implement anything else)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e017a69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Problem 1: Markov chain estimation + hitting times ===\n",
      "Estimated P_hat:\n",
      " [[0.2   0.6   0.2   0.   ]\n",
      " [0.167 0.167 0.5   0.167]\n",
      " [0.2   0.2   0.2   0.4  ]\n",
      " [0.5   0.25  0.    0.25 ]]\n",
      "Is valid transition matrix? True\n",
      "\n",
      "Comparison table:\n",
      "    target_state  MC_estimate  theoretical  abs_diff\n",
      "0             0       1.0000     1.000000  0.000000\n",
      "1             1       3.0288     2.024390  1.004410\n",
      "2             2       4.3002     3.317073  0.983127\n",
      "3             3       6.7030     5.682927  1.020073\n"
     ]
    }
   ],
   "source": [
    "def problem1_main():\n",
    "    print(\"\\n=== Problem 1: Markov chain estimation + hitting times ===\")\n",
    "\n",
    "    # 1) Estimate P\n",
    "    P_hat = comp_transition_matrix(X_t, N_states)\n",
    "    print(\"Estimated P_hat:\\n\", np.round(P_hat, 3))\n",
    "\n",
    "    # 2) Validate\n",
    "    print(\"Is valid transition matrix?\", is_transition_matrix(P_hat))\n",
    "\n",
    "    # 3) Expected steps from given start state to all states\n",
    "    start_state = 0\n",
    "\n",
    "    # simulation\n",
    "    mc = hitting_times_sim(P_hat, start_state=start_state, n_sim=5000)\n",
    "\n",
    "    # Theory (linear system)\n",
    "    th = theoretical_hitting_times(P_hat, start_state=start_state)\n",
    "\n",
    "    # 4) Compare\n",
    "    df = pd.DataFrame({\n",
    "        \"target_state\": np.arange(N_states),\n",
    "        \"MC_estimate\": mc,\n",
    "        \"theoretical\": th,\n",
    "        \"abs_diff\": np.abs(mc - th),\n",
    "    })\n",
    "    print(\"\\nComparison table:\\n\", df)\n",
    "problem1_main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a45403",
   "metadata": {},
   "source": [
    "PROBLEM 2: Cost-Sensitive Classification\n",
    "\n",
    "You are given a binary classification problem for fraud detection.\n",
    "\n",
    "Class labels:\n",
    "\n",
    "    y = 1 => fraud\n",
    "\n",
    "    y = 0 => ok\n",
    "\n",
    "\n",
    "\n",
    "The costs of classification outcomes are:\n",
    "    TP = 0, TN = 0, FP = 100, FN = 500\n",
    "\n",
    "Tasks:\n",
    "1. Train an SVM classifier.\n",
    "2. Compute classification costs at a fixed threshold (0.5).\n",
    "3. Evaluate total cost for multiple probability thresholds.\n",
    "4. Find the threshold that minimizes total cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "cc6371ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.250243</td>\n",
       "      <td>-0.863902</td>\n",
       "      <td>-0.307019</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.380736</td>\n",
       "      <td>0.018756</td>\n",
       "      <td>-0.559577</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.126431</td>\n",
       "      <td>2.055912</td>\n",
       "      <td>0.973126</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.806991</td>\n",
       "      <td>2.104160</td>\n",
       "      <td>-0.211368</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.059649</td>\n",
       "      <td>0.652374</td>\n",
       "      <td>-0.437259</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2        x3  fraud\n",
       "0 -0.250243 -0.863902 -0.307019      0\n",
       "1 -0.380736  0.018756 -0.559577      0\n",
       "2  1.126431  2.055912  0.973126      1\n",
       "3  0.806991  2.104160 -0.211368      1\n",
       "4  0.059649  0.652374 -0.437259      0"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "costs = {\"TP\": 0, \"TN\": 0, \"FP\": 100, \"FN\": 500}\n",
    "\n",
    "\n",
    "def generate_fraud_table(seed=0, n=3000, fraud_rate=0.05):\n",
    "    \"\"\"\n",
    "    Generate a simple fraud dataset as a single table. The table contains:\n",
    "        - numerical features: x1, x2, x3\n",
    "        - binary target column: fraud (1 = fraud, 0 = legitimate)\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # Target variable\n",
    "    fraud = (rng.random(n) < fraud_rate).astype(int)\n",
    "\n",
    "    # Features\n",
    "    x1 = rng.normal(0, 1, size=n)\n",
    "    x2 = rng.normal(0, 1, size=n)\n",
    "    x3 = rng.normal(0, 1, size=n)\n",
    "\n",
    "    #  fraud cases are shifted\n",
    "    x1[fraud == 1] += 2.0\n",
    "    x2[fraud == 1] += 1.0\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"x1\": x1,\n",
    "        \"x2\": x2,\n",
    "        \"x3\": x3,\n",
    "        \"fraud\": fraud,\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "fraud_data = generate_fraud_table()\n",
    "\n",
    "fraud_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031231e8",
   "metadata": {},
   "source": [
    "Fill in the methods in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "4d03aae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "def train_test_split_table(df):\n",
    "    \"\"\"\n",
    "    Split a data table into training and test sets.\n",
    "\n",
    "    Returns:\n",
    "        X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    # implement splitting\n",
    "    # first, decide what are features and what are target \n",
    "    X = df[[\"x1\", \"x2\", \"x3\"]]\n",
    "    y = df[\"fraud\"]\n",
    "\n",
    "    # then split into train and test\n",
    "    split = int(0.8 * df.shape[0])\n",
    "    X_train = X[:split]\n",
    "    X_test = X[split:]\n",
    "    y_train = y[:split]\n",
    "    y_test = y[split:]\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def fit_linear_svm(fraud_data):\n",
    "    \"\"\"\n",
    "    Fit a linear SVM classifier.\n",
    "\n",
    "    Args: data table\n",
    "\n",
    "    Returns:\n",
    "        predicted labels of length len(y_test) \n",
    "    \"\"\"\n",
    "    # define our model\n",
    "    clf = LinearSVC(\n",
    "        C=1.0,\n",
    "        max_iter=10_000,\n",
    "        random_state=0\n",
    "    )\n",
    "\n",
    "    # split the data into trian and test:\n",
    "    X_train, X_test, y_train, y_test = train_test_split_table(fraud_data)\n",
    "    #   Fit the SVM using X_train and y_train and predict the label using y_test. return y_pred\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    return clf\n",
    "\n",
    "\n",
    "def confusion_counts(y_true, y_pred):\n",
    "    \n",
    "    \"\"\"\n",
    "    Computes TP, TN, FP, FN.\n",
    "    \"\"\"\n",
    "    \n",
    "    TP_est, TN_est, FP_est, FN_est = 0,0,0,0 \n",
    "    \n",
    "    # Here you Ccmpute TP, TN, FP, FN.\n",
    "    TP_est = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    FP_est = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    TN_est = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    FN_est = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    \n",
    "    return {\"TP\": TP_est, \"TN\": TN_est, \"FP\": FP_est, \"FN\": FN_est}\n",
    "\n",
    "\n",
    "def total_cost(counts):\n",
    "    \"\"\"\n",
    "    Compute total cost from confusion counts.\n",
    "\n",
    "    \"\"\"\n",
    "    # Multiply counts by costs and sum\n",
    "    total_cost = (counts[\"FP\"] * 100) + (counts[\"FN\"] * 500)\n",
    "    \n",
    "    return total_cost\n",
    "\n",
    "# evaluate how the classification cost changes when you change the decision threshold.\n",
    "def sweep_thresholds(y_true, thresholds, X, clf):\n",
    "    \"\"\"\n",
    "    Evaluate total cost for a range of thresholds.\n",
    "    \n",
    "    Here, clf is your trained SVM classifier\n",
    "    \"\"\"\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    # note: here, I define y_probs to be just a decision function. Think: does it need to be calibrated to be used in this problem?\n",
    "    y_probs = clf.decision_function(X)\n",
    "\n",
    "    for t in thresholds:\n",
    "        # 1) compute the prediction for a chosen theshold\n",
    "        y_pred = (y_probs >= t).astype(int)\n",
    "\n",
    "        # 2) Confusion matrix counts  (previoulsy implemented by you)\n",
    "        counts = confusion_counts(y_true, y_pred)\n",
    "\n",
    "        # 3) Total cost (previoulsly implemented by you)\n",
    "        cost = total_cost(counts)\n",
    "\n",
    "        # 4) Store results\n",
    "        results.append({\n",
    "            \"threshold\": t,\n",
    "            \"TP\": counts[\"TP\"],\n",
    "            \"TN\": counts[\"TN\"],\n",
    "            \"FP\": counts[\"FP\"],\n",
    "            \"FN\": counts[\"FN\"],\n",
    "            \"total_cost\": cost,\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12c44a4",
   "metadata": {},
   "source": [
    "When you are done, run the following cell (no need to implement anything else)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "4235863e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset head:\n",
      "         x1        x2        x3  fraud\n",
      "0 -0.250243 -0.863902 -0.307019      0\n",
      "1 -0.380736  0.018756 -0.559577      0\n",
      "2  1.126431  2.055912  0.973126      1\n",
      "3  0.806991  2.104160 -0.211368      1\n",
      "4  0.059649  0.652374 -0.437259      0 \n",
      "\n",
      "Threshold sweep results:\n",
      "    threshold  TP   TN   FP  FN  total_cost\n",
      "0        -2.0  29  185  386   0       38600\n",
      "1        -1.8  29  241  330   0       33000\n",
      "2        -1.6  29  306  265   0       26500\n",
      "3        -1.4  29  387  184   0       18400\n",
      "4        -1.2  29  438  133   0       13300\n",
      "5        -1.0  29  482   89   0        8900\n",
      "6        -0.8  27  518   53   2        6300\n",
      "7        -0.6  26  537   34   3        4900\n",
      "8        -0.4  24  553   18   5        4300\n",
      "9        -0.2  19  564    7  10        5700\n",
      "10        0.0  14  566    5  15        8000\n",
      "11        0.2  12  567    4  17        8900\n",
      "12        0.4   7  568    3  22       11300\n",
      "13        0.6   3  569    2  26       13200\n",
      "14        0.8   2  571    0  27       13500\n",
      "15        1.0   1  571    0  28       14000\n",
      "16        1.2   1  571    0  28       14000\n",
      "17        1.4   0  571    0  29       14500\n",
      "18        1.6   0  571    0  29       14500\n",
      "19        1.8   0  571    0  29       14500\n",
      "20        2.0   0  571    0  29       14500\n",
      "Optimal threshold: threshold       -0.4\n",
      "TP              24.0\n",
      "TN             553.0\n",
      "FP              18.0\n",
      "FN               5.0\n",
      "total_cost    4300.0\n",
      "Name: 8, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    df = fraud_data\n",
    "\n",
    "    print(\"Dataset head:\")\n",
    "    print(df.head(), \"\\n\")\n",
    "\n",
    "    # split in train and test:\n",
    "    _, X_test, _, y_test = train_test_split_table(df)\n",
    "    # Fit linear SVM\n",
    "    clf = fit_linear_svm(df)\n",
    "\n",
    "    # thresholds\n",
    "    thresholds = np.linspace(-2.0, 2.0, 21)\n",
    "    df_results = sweep_thresholds(\n",
    "        y_test,\n",
    "        thresholds,\n",
    "        X_test,\n",
    "        clf,\n",
    "    )\n",
    "\n",
    "    print(\"Threshold sweep results:\")\n",
    "    print(df_results)\n",
    "\n",
    "    # 6) Identify optimal threshold\n",
    "    best_row = df_results.loc[df_results[\"total_cost\"].idxmin()]\n",
    "    print(\"Optimal threshold:\", best_row)\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f8baea",
   "metadata": {},
   "source": [
    "PROBLEM 3: Confidence estimation of the cost\n",
    "\n",
    "In Problem 2, you trained a classifier, selected a decision threshold, evaluated its performance on a test set, and computed the cost\n",
    "\n",
    "In this problem, you will quantify the uncertainty of this estimated cost. Each observation in the test set produces a cost depending on the\n",
    "classification outcome:\n",
    "\n",
    "    TN: 0\n",
    "   \n",
    "    FP: 100\n",
    "\n",
    "    TP: 0\n",
    "\n",
    "    FN: 500\n",
    "\n",
    "Thus, the cost per observation is a bounded random variable taking\n",
    "values in the interval [0, 500].\n",
    "\n",
    "Tasks:\n",
    "1. Compute the average cost per observation on the test set.\n",
    "2. Use Hoeffdingâ€™s inequality to construct a 95% confidence interval\n",
    "   for the true expected cost of the classifier.\n",
    "3. Interpret the resulting interval:\n",
    "   - What does it say about the reliability of your estimate?\n",
    "   - Is the interval likely to be tight or conservative? Why?\n",
    "\n",
    "You may assume that test observations are independent and identically\n",
    "distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "2bfb275e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_observation_cost(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute per-observation cost vector.\n",
    "    \"\"\"\n",
    "    \n",
    "    # here, you will compute the average cost using the test set\n",
    "    costs = np.zeros_like(y_true, dtype=float)\n",
    "    costs[(y_true == 0) & (y_pred == 1)] == 100\n",
    "    costs[(y_true == 1) & (y_pred == 0)] == 500\n",
    "    \n",
    "    return costs\n",
    "\n",
    "\n",
    "def hoeffding_ci(per_obs_costs, mean, n, a, b, delta=0.05):\n",
    "    \"\"\"\n",
    "    Hoeffding confidence interval\n",
    "    \"\"\"\n",
    "    # Step 1: deterministic costs per observation\n",
    "    c = per_obs_costs\n",
    "\n",
    "    # Step 2:   average cost\n",
    "    mean_cost = np.mean(c)\n",
    "\n",
    "    # Step 3: construct a Hoeffding intevral of the estimated cost\n",
    "    epsilon = (b-a) * np.sqrt(np.log(2/delta) / 2 * n)\n",
    "    ci = [mean_cost - epsilon, mean_cost + epsilon]\n",
    "    \n",
    "    \n",
    "    return ci\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
